{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 23:52:53.069249: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-13 23:52:53.075943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731559973.083930 3558848 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731559973.086352 3558848 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 23:52:53.095235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from DataUtils import *\n",
    "from hfUtils import *\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Load The Data to RAM\n",
    "Below is the function to call to get the data loaded and formatted into prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts, test_prompts, subjects = load_mmlu_to_ram('./MMLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: college medicine\n",
      "--------------------\n",
      "Training Prompt:\n",
      "The following are multiple choice questions (with answers) about college medicine.\n",
      "\n",
      "Glucose is transported into the muscle cell:\n",
      "A. via protein transporters called GLUT4.\n",
      "B. only in the presence of insulin.\n",
      "C. via hexokinase.\n",
      "D. via monocarbylic acid transporters.\n",
      "Answer: A\n",
      "\n",
      "Which of the following is not a true statement?\n",
      "A. Muscle glycogen is broken down enzymatically to glucose-1-phosphate\n",
      "B. Elite endurance runners have a high proportion of Type I fibres in their leg muscles\n",
      "C. Liver glycogen is important in the maintenance of the blood glucose concentration\n",
      "D. Insulin promotes glucose uptake by all tissues in the body\n",
      "Answer: D\n",
      "\n",
      "In a genetic test of a newborn, a rare genetic disorder is found that has X-linked recessive transmission. Which of the following statements is likely true regarding the pedigree of this disorder?\n",
      "A. All descendants on the maternal side will have the disorder.\n",
      "B. Females will be approximately twice as affected as males in this family.\n",
      "C. All daughters of an affected male will be affected.\n",
      "D. There will be equal distribution of males and females affected.\n",
      "Answer: C\n",
      "\n",
      "A high school science teacher fills a 1 liter bottle with pure nitrogen and seals the lid. The pressure is 1.70 atm, and the room temperature is 25°C. Which two variables will both increase the pressure of the system, if all other variables are held constant?\n",
      "A. Increasing temperature, increasing moles of gas\n",
      "B. Increasing temperature, increasing volume\n",
      "C. Decreasing volume, decreasing temperature\n",
      "D. Decreasing moles of gas, increasing volume\n",
      "Answer: A\n",
      "\n",
      "An expected side effect of creatine supplementation is:\n",
      "A. muscle weakness.\n",
      "B. gain in body mass.\n",
      "C. muscle cramps.\n",
      "D. loss of electrolytes.\n",
      "Answer: B\n",
      "\n",
      "\n",
      "--------------------\n",
      "Test Question: A dentist that is performing procedures in his clinic is brought out to the front desk one day to handle a dispute between one of his patients and the clerk. The patient is a middle-aged businessman who is irate and creating a scene because he was told he would have to see the dental hygienist instead of the dentist. The patient loudly rants that he makes too much money to be subjected to treatment by a half-trained associate. The clerk explains to the dentist that the patient was 40 minutes late to his appointment, and the only opening now was with the hygienist. The patient snaps back that his time is worth more than any of the people in the office. What personality disorder is this patient likely exhibiting?\n",
      "A. Histrionic\n",
      "B. Narcissistic\n",
      "C. Paranoid\n",
      "D. Obsessive-compulsive\n",
      "Answer: \n",
      "Expected Answer: C\n",
      "Subject: college biology\n",
      "--------------------\n",
      "Training Prompt:\n",
      "The following are multiple choice questions (with answers) about college biology.\n",
      "\n",
      "Which of the following represents an accurate statement concerning arthropods?\n",
      "A. They possess an exoskeleton composed primarily of peptidoglycan.\n",
      "B. They possess an open circulatory system with a dorsal heart.\n",
      "C. They are members of a biologically unsuccessful phylum incapable of exploiting diverse habitats and nutrition sources.\n",
      "D. They lack paired, jointed appendages.\n",
      "Answer: B\n",
      "\n",
      "In a given population, 1 out of every 400 people has a cancer caused by a completely recessive allele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is the expected proportion of individuals who carry the b allele but are not expected to develop the cancer?\n",
      "A. 1/400\n",
      "B. 19/400\n",
      "C. 20/400\n",
      "D. 38/400\n",
      "Answer: D\n",
      "\n",
      "The presence of homologous structures in two different organisms, such as the humerus in the front limb of a human and a bird, indicates that\n",
      "A. the human and bird are polyphyletic species\n",
      "B. a human's and bird's evolution is convergent\n",
      "C. the human and bird belong to a clade\n",
      "D. the human and bird developed by analogy\n",
      "Answer: C\n",
      "\n",
      "According to the pressure-flow model of movement of phloem contents, photosynthate movement from source to sink is driven by\n",
      "A. an ATP-dependent pressure-flow pump\n",
      "B. a water-pressure potential gradient\n",
      "C. transpiration\n",
      "D. apoplastic diffusion\n",
      "Answer: B\n",
      "\n",
      "Which of the following contain DNA sequences required for the segregation of chromosomes in mitosis and meiosis?\n",
      "A. Telomeres\n",
      "B. Centromeres\n",
      "C. Nucleosomes\n",
      "D. Spliceosomes\n",
      "Answer: B\n",
      "\n",
      "\n",
      "--------------------\n",
      "Test Question: The target of digestion of a nucleosome dimer to nucleosome monomers by DNase is\n",
      "A. the H1 histone\n",
      "B. histones H2A, H2B, H3, and H4\n",
      "C. the nucleosome core\n",
      "D. linker DNA\n",
      "Answer: \n",
      "Expected Answer: D\n"
     ]
    }
   ],
   "source": [
    "n_examples = 2\n",
    "n_smaples = 1\n",
    "\n",
    "for i in range(n_examples):\n",
    "    rnd_subject = np.random.choice(len(subjects))\n",
    "    \n",
    "    print('Subject:', subjects[rnd_subject])\n",
    "    print(\"--------------------\")\n",
    "    print(\"Training Prompt:\")\n",
    "    print(train_prompts[rnd_subject])\n",
    "    print('--------------------')\n",
    "    \n",
    "    for j in range(n_smaples):\n",
    "        rnd_question = np.random.choice(len(test_prompts[rnd_subject]))\n",
    "        \n",
    "        print('Test Question:', test_prompts[rnd_subject][rnd_question][0])\n",
    "        print('Expected Answer:', test_prompts[rnd_subject][rnd_question][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing A Model\n",
    "For now let's test google/gemma-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3d82c11e424db7b37b0f927b53bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model = load_model_and_tokenizer(\"meta-llama/Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the equation 2 + x + 5 - x + 3x = 10, we need to combine like terms.\n",
      "\n",
      "First, let's combine the constants (numbers without variables):\n",
      "2 + 5 = 7\n",
      "\n",
      "Now, the equation becomes:\n",
      "7 + x - x + 3x = 10\n",
      "\n",
      "Next, let's combine the x terms:\n",
      "-x + 3x = 2x\n",
      "\n",
      "Now, the equation becomes:\n",
      "7 + 2x = 10\n",
      "\n",
      "To isolate the variable x, we need to get rid of the constant 7 on the left side of the equation. We can do this by subtracting 7 from both sides:\n",
      "7 - 7 + 2x = 10 - 7\n",
      "0 + 2x = 3\n",
      "\n",
      "Now, we can simplify the left side of the equation:\n",
      "2x = 3\n",
      "\n",
      "Finally, to solve for x, we need to get x by itself. We can do this by dividing both sides of the equation by 2:\n",
      "2x / 2 = 3 / 2\n",
      "x = 3/2\n",
      "x = 1.5\n",
      "\n",
      "So, the answer to the equation 2 + x + 5 - x + 3x\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assitant\"},\n",
    "    {\"role\": \"user\", \"content\": \"what is the answer to 2+x+5-x+3x=10\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.01,\n",
    "    top_p=0.1,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is the capital of France? Paris\\nWhat is the capital of England? London\\nWhat is the capital of Australia? Canberra\\nWhat is the capital of Canada? Ottawa\\nWhat is the capital of the United States? Washington D.C.\\nWhat is the capital of China? Beijing\\nWhat is the capital of Japan? Tokyo\\nWhat is the capital of India? New Delhi\\nWhat is the capital of Brazil? Brasília\\nWhat is the capital of Russia? Moscow\\nWhat is the capital of South Africa? Pretoria (administrative capital) and Cape Town (legislative capital) and Bloemfontein (judicial capital)\\nWhat is the capital of Egypt? Cairo\\nWhat is the capital of South Korea? Seoul\\nWhat is the capital of Italy? Rome\\nWhat is the capital of Germany? Berlin\\nWhat is the capital of Spain? Madrid\\nWhat is the capital of Poland? Warsaw\\nWhat is the capital of Argentina? Buenos Aires\\nWhat is the capital of Mexico? Mexico City\\nWhat is'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "chat_history.append({''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dac6ac15c824ad0a45a10d58127872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject abstract algebra accuracy: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f10ac695af452388581501e7bbc589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject anatomy accuracy: 0.6518518518518519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88901238750404c94758c684e84a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject astronomy accuracy: 0.7368421052631579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7832410f154fa7a14be8dd019d320f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject business ethics accuracy: 0.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bae46e943f64f33b2c39ec0b7eb0dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject clinical knowledge accuracy: 0.7396226415094339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7218fb768f054204b649578fa6f2ad7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college biology accuracy: 0.7777777777777778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be369ec4263496e957d0d5a5f85a1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college chemistry accuracy: 0.52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440ac7403671473699e3798a799330bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college computer science accuracy: 0.55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82756fa0bb5748a892db3eb3a650e2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college mathematics accuracy: 0.37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b74babf5bc04a4d945071b9fe8078aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college medicine accuracy: 0.6763005780346821\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2fa6788a51413283167acdf30dd41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject college physics accuracy: 0.4411764705882353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14763da6f474fc584e7c5e3a78a4eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject computer security accuracy: 0.81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3622c5614d74d07bf5ae3f8d9d300d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject conceptual physics accuracy: 0.5872340425531914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce28060ffafe4645b0375d1dc2ee9a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject econometrics accuracy: 0.4649122807017544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973087e3f3b4418a8877a04ab502ed3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject electrical engineering accuracy: 0.6551724137931034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67be54110f224b60869875d36ee0c52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject elementary mathematics accuracy: 0.4497354497354497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c0222b3beb4b3d967c4ffe39d94edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject formal logic accuracy: 0.5634920634920635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd850004dad84e739f3a0feb30b524bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject global facts accuracy: 0.31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83508c5f5d5840b89c2a7169173c68dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school biology accuracy: 0.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3d8f452c044d56af75db3b555314eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school chemistry accuracy: 0.5763546798029556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdc9353415d4e8a8e8e46cf4309ffcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school computer science accuracy: 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a0ed18eb23497a9fbd67c75c1fb57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school european history accuracy: 0.7757575757575758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537e6ad2eace45858392e2018f79b0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school geography accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4d95e94fd5445896248e0aff1dce03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school government and politics accuracy: 0.917098445595855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e61540282449bf8ad21af3fd3cf898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school macroeconomics accuracy: 0.6692307692307692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a56f056ce94ea29bd4117257b5c5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school mathematics accuracy: 0.3814814814814815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6583746399d949759935c73f7f9c029b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school microeconomics accuracy: 0.7647058823529411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e807b5c504a0f8f7b5eaf14aa3ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school physics accuracy: 0.3841059602649007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e526b8160f4f1ea3913e69b5619083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school psychology accuracy: 0.8605504587155963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f4e856258a45fa81df03caee696658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school statistics accuracy: 0.5601851851851852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc823d9b29d44f65aa29db856dd16168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school us history accuracy: 0.8137254901960784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c63bb81ff749c483d2bdf9feb03250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject high school world history accuracy: 0.8438818565400844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9068b7810d594a029232729cabcfb6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/223 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject human aging accuracy: 0.672645739910314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dcf5b8cf664bce909cc1b682e829e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject human sexuality accuracy: 0.8091603053435115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d11ba2cafe4c10a5051eb7ee862a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject international law accuracy: 0.8347107438016529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfebdef83ce43fca6400d553ffa351a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject jurisprudence accuracy: 0.7592592592592593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eefb01819546649627bad53b5d718d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject logical fallacies accuracy: 0.7914110429447853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd36b0655e184299812eddcd60c1c450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject machine learning accuracy: 0.5446428571428571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65cbc87fa0348d6a04da09145722794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject management accuracy: 0.8058252427184466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fafac3c8b2420db32be84229fad4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject marketing accuracy: 0.8803418803418803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d4ea2ae33e4ca38c33fb5d38461c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject medical genetics accuracy: 0.81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565599fa519543b6babb70f4bf68c9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject miscellaneous accuracy: 0.8160919540229885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf47c1fbed5c4867be84384ec4c39c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject moral disputes accuracy: 0.7283236994219653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889b182a1be546a5b6f2219a616b13c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/895 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject moral scenarios accuracy: 0.49162011173184356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50dc6331b7b4738ac221bde43f5d79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject nutrition accuracy: 0.7483660130718954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216f6a3bf9854bcfa5f605c7f76b8bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject philosophy accuracy: 0.7170418006430869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5ea96730a2453594937df49dcdf5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject prehistory accuracy: 0.7160493827160493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210756b5f3f849c1a286122d7ce5ea1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject professional accounting accuracy: 0.4432624113475177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a475b631d243a0bc1a53391a18f562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject professional law accuracy: 0.5058670143415906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbc2a833a1541a1a8ce66b8823a2858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject professional medicine accuracy: 0.7757352941176471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a631bdebe28b4d30a2f0e71a686469c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject professional psychology accuracy: 0.7140522875816994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fc4a0bad7f41af9cf81dd3e6125c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject public relations accuracy: 0.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21c946c7d2743e8adfe9f139a2bb745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject security studies accuracy: 0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362dad5ba85a4ce3b4e016c3d281e928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject sociology accuracy: 0.835820895522388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330613928010437aa713ed3978d65dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject us foreign policy accuracy: 0.87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcb2e04cfeb4b19b0ffa483c61fc836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject virology accuracy: 0.5240963855421686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b17fa3048f4be18d0a99a9b9ea7f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject world religions accuracy: 0.8128654970760234\n"
     ]
    }
   ],
   "source": [
    "# run all test prompts through the model and get the predictions\n",
    "# from transformers import pipeline\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    accuracies = []\n",
    "    for i,subject in enumerate(subjects):\n",
    "        train_prompt = train_prompts[i]\n",
    "        predictions.append([])\n",
    "        accuracies.append(0)\n",
    "        for j in tqdm(range(len(test_prompts[i]))):\n",
    "            input_prompt = train_prompt + test_prompts[i][j][0]\n",
    "            expected_output = test_prompts[i][j][1]\n",
    "            \n",
    "            input_ids = tokenizer.encode(input_prompt, return_tensors='pt').to(model.device)\n",
    "            logits = model(input_ids=input_ids).logits[0, -1]\n",
    "            \n",
    "            probs = (\n",
    "                torch.nn.functional.softmax(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            logits[tokenizer(\"A\").input_ids[-1]],\n",
    "                            logits[tokenizer(\"B\").input_ids[-1]],\n",
    "                            logits[tokenizer(\"C\").input_ids[-1]],\n",
    "                            logits[tokenizer(\"D\").input_ids[-1]],\n",
    "                        ]\n",
    "                    ).float(),\n",
    "                    dim=0,\n",
    "                )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            pred = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}[np.argmax(probs)]\n",
    "        \n",
    "            # output = model.generate(input_ids, max_length=input_ids.shape[1]+1, num_return_sequences=1, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "            # prediction = tokenizer.decode(output[0], skip_special_tokens=True)[len(input_prompt):]\n",
    "            \n",
    "            predictions[-1].append(pred)\n",
    "            \n",
    "            if pred == expected_output:\n",
    "                accuracies[-1] += 1\n",
    "                \n",
    "        accuracies[-1] /= len(test_prompts[i])\n",
    "        print(f\"Subject {subject} accuracy: {accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 67.31%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average accuracy: {np.mean(accuracies)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 2\n",
    "n_smaples = 1\n",
    "\n",
    "for i in range(n_examples):\n",
    "    rnd_subject = np.random.choice(len(subjects))\n",
    "    \n",
    "    print('Subject:', subjects[rnd_subject])\n",
    "    print(\"--------------------\")\n",
    "    print(\"Training Prompt:\")\n",
    "    print(train_prompts[rnd_subject])\n",
    "    print('--------------------')\n",
    "    \n",
    "    for j in range(n_smaples):\n",
    "        rnd_question = np.random.choice(len(test_prompts[rnd_subject]))\n",
    "        \n",
    "        print('Test Question:', test_prompts[rnd_subject][rnd_question][0])\n",
    "        print('Expected Answer:', test_prompts[rnd_subject][rnd_question][1])\n",
    "        print('Predicted Answer:', predictions[rnd_subject][rnd_question])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
