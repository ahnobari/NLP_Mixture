\begin{table}[htbp]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\textbf{Model} & \textbf{Math} & \textbf{GSM8k} & \textbf{Math OAI} & \textbf{GSM Hard} & \textbf{MBPP} & \textbf{MBPP++} & \textbf{MMLU} \\
\midrule
\multicolumn{8}{l}{\textbf{Base Model}} \\
Instruct & 48.3 & 68.4 & 48.6 & 34.5 & 72.2 & 60.8 & 66.4 \\
\midrule
\multicolumn{8}{l}{\textbf{Fine-tuned Models}} \\
NarrativAI Reflection & 47.6 & 61.6 & 45.8 & 30.6 & 69.8 & 58.5 & 66.1 \\
infinity 3M Kobo & 25.9 & 68.7 & 27.4 & 36.5 & 69.0 & 57.1 & 63.9 \\
tulu 2 & 13.3 & 56.8 & 13.8 & 23.8 & 59.5 & 47.4 & 61.2 \\
Pretrained & 2.5 & 4.0 & 2.6 & 1.8 & 62.2 & 52.1 & 63.6 \\
zephyr & 13.4 & 33.2 & 13.0 & 18.3 & 47.4 & 39.9 & 64.1 \\
Magpie Align SFT & 28.7 & 70.0 & 29.4 & 33.4 & 63.8 & 52.1 & 63.6 \\
WhiteRabbitNeo 2 & 11.1 & 28.2 & 12.2 & 14.5 & 64.8 & 52.6 & 63.9 \\
Natsumura Assistant & 24.3 & 69.3 & 22.2 & 31.1 & 66.4 & 54.2 & 61.9 \\
Nvidia OpenMath 2 & 63.1 & 89.3 & 62.6 & 45.5 & 28.3 & 24.6 & 38.7 \\
Hermes 3 & 13.2 & 45.7 & 12.8 & 21.2 & 47.1 & 38.6 & 63.8 \\
BAdam & 5.7 & 14.3 & 5.2 & 7.7 & 25.9 & 21.7 & 29.4 \\
Instruct-Spatial-SQL & 45.9 & 35.8 & 43.8 & 20.5 & 71.7 & 62.2 & 66.1 \\
\midrule
\multicolumn{8}{l}{\textbf{All Checkpoints Merging}} \\
Average Merging & 11.0 & 22.2 & 10.0 & 10.0 & 69.8 & 57.4 & 66.0 \\
Mask Merging & 10.3 & 17.0 & 8.4 & 10.0 & 70.6 & 58.2 & 66.1 \\
Activation Aware Relaxation & 13.9 & 23.0 & 11.2 & 12.8 & 48.4 & 38.1 & 60.6 \\
Ties Merging & 24.0 & 62.2 & 23.4 & 25.5 & 25.1 & 20.1 & 46.1 \\
Widen Merging & 0.2 & 0.8 & 0.4 & 0.4 & 0.0 & 0.0 & 25.2 \\
Task_Arithmetic & 0.2 & 0.7 & 0.2 & 0.1 & 0.0 & 0.0 & 23.0 \\
\midrule
\multicolumn{8}{l}{\textbf{Filtered From Instruct Merging}} \\
Average Merging & 51.7 & 78.2 & 49.0 & 41.2 & 59.5 & 48.4 & 62.4 \\
Mask Merging & 49.8 & 76.3 & 47.4 & 40.3 & 61.1 & 48.9 & 63.2 \\
Activation Aware Relaxation & 64.5 & 90.7 & 64.8 & 49.0 & 32.5 & 27.0 & 45.3 \\
Task Arithmetic Merging & 62.5 & 89.6 & 61.0 & 45.2 & 29.9 & 26.5 & 38.6 \\
Ties Merging & 60.3 & 88.6 & 59.0 & 44.7 & 33.6 & 28.0 & 52.8 \\
Widen Merging & 59.7 & 81.6 & 59.0 & 40.6 & 24.6 & 20.9 & 45.0 \\
\midrule
\multicolumn{8}{l}{\textbf{Filtered From Pretrained Merging}} \\
Task Arithmatic Merging & 40.2 & 63.0 & 37.8 & 19.9 & 1.9 & 1.3 & 25.3 \\
Average Merging & 42.9 & 42.6 & 45.4 & 24.9 & 66.4 & 55.3 & 64.3 \\
Mask Merging & 38.9 & 35.4 & 41.8 & 21.3 & 66.9 & 55.3 & 64.7 \\
Ties Merging & 51.9 & 81.0 & 47.8 & 39.9 & 29.1 & 23.8 & 52.2 \\
Widen Merging & 59.7 & 81.6 & 59.0 & 40.6 & 24.6 & 20.9 & 45.0 \\
\bottomrule
\end{tabular}
}
\caption{Comprehensive Model Performance Across Different Benchmarks}
\label{tab:comprehensive-results}
\begin{tablenotes}
\small
\item All values are reported as percentages (\%).
\item MBPP and MBPP++ report pass@1 accuracy.
\item MMLU reports overall accuracy across all categories.
\end{tablenotes}
\end{table}