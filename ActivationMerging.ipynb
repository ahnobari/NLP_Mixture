{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MergeModels.ActivationMerging import get_calib_feat, activation_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('checkpoints.yml', 'r') as file:\n",
    "    checkpoints = yaml.safe_load(file)\n",
    "\n",
    "pretrained_model_name = checkpoints['Instruct'][0]['HF_Repo']\n",
    "finetuned_model_names = [item[next(iter(item))][0]['HF_Repo'] for item in checkpoints['Checkpoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuned_model_names = ['markrodrigo/Llama-3.1-8B-Instruct-Spatial-SQL-1.0', 'nvidia/OpenMath2-Llama3.1-8B', 'passthepizza/NarrativAI-Reflection']\n",
    "# pretrained_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "finetuned_model_names = ['markrodrigo/Llama-3.1-8B-Instruct-Spatial-SQL-1.0', 'nvidia/OpenMath2-Llama3.1-8B', 'passthepizza/NarrativAI-Reflection','meta-llama/Llama-3.1-8B-Instruct']\n",
    "pretrained_model_name = 'meta-llama/Llama-3.1-8B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.1-8B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MergeModels.ActivationMerging._utils import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdceeffcda234d2c8103113d9535a6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe78bd74819d428abd6b5555519992fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9538302e60c34563b058c31d94a52865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cd2e728f244a17bc718082c6e30597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading calibration dataset...\n",
      "getting calibration features...\n",
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242c7dae49f54f91ba4959331f60fd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6689f85f2214b6f8ebe31bdbe25f446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7573 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e38f4563bc14958a77412fe14bd20b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7713a7c15884a69beadbe892975c85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b936e93a99774127acd90ac64f7b8113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging models...\n"
     ]
    }
   ],
   "source": [
    "print('loading models...')\n",
    "models_to_merge, finetuned_tokenizers, finetuned_configs = [], [], []\n",
    "for finetuned_model_name in finetuned_model_names:\n",
    "    try:\n",
    "        finetuned_model = AutoModelForCausalLM.from_pretrained(finetuned_model_name, device_map='cpu', torch_dtype=torch.bfloat16)\n",
    "        finetuned_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_name)\n",
    "        finetuned_config = AutoConfig.from_pretrained(finetuned_model_name)\n",
    "        models_to_merge.append(finetuned_model)\n",
    "        finetuned_tokenizers.append(finetuned_tokenizer)\n",
    "        finetuned_configs.append(finetuned_config)\n",
    "    except Exception as e:\n",
    "        print(f\"Model {finetuned_model_name} could not be loaded.\")\n",
    "        print(f\"Reason: {e}\")\n",
    "\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=pretrained_model_name, torch_dtype=torch.bfloat16)\n",
    "pretrained_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=pretrained_model_name)\n",
    "pretrained_config = AutoConfig.from_pretrained(pretrained_model_name_or_path=pretrained_model_name)\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "# align the tokens of pretrained and finetuned tokenizer\n",
    "align_tokenizers_and_embeddings(pretrained_model=pretrained_model, pretrained_tokenizer=pretrained_tokenizer,\n",
    "                                pretrained_config=pretrained_config, finetuned_models=models_to_merge,\n",
    "                                finetuned_tokenizers=finetuned_tokenizers, finetuned_configs=finetuned_configs, logger=logger)\n",
    "print('loading calibration dataset...')\n",
    "dataset = load_dataset(\"mit-han-lab/pile-val-backup\", split=\"validation\")\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "    \n",
    "print('getting calibration features...')\n",
    "scale_dicts = []\n",
    "for i in range(len(models_to_merge)):\n",
    "    models_to_merge[i].to('cuda')\n",
    "    tokenizer = finetuned_tokenizers[i]\n",
    "    scale_dict = get_calib_feat(models_to_merge[i], tokenizer, dataset)\n",
    "    scale_dicts.append(scale_dict)\n",
    "    models_to_merge[i].to('cpu')\n",
    "\n",
    "pretrained_model.to('cuda')\n",
    "pretrained_scale_dict = get_calib_feat(pretrained_model, pretrained_tokenizer,dataset)\n",
    "pretrained_model.to('cpu')\n",
    "\n",
    "layer_mapping_dicts = []\n",
    "for i in range(len(models_to_merge)):\n",
    "    layer_mapping_dict = {}\n",
    "    for name, param in models_to_merge[i].named_modules():\n",
    "        if isinstance(param, nn.Linear):\n",
    "            layer_mapping_dict[name] = param\n",
    "    layer_mapping_dicts.append(layer_mapping_dict)\n",
    "\n",
    "pretrained_layer_mapping_dict = {}\n",
    "for name, param in pretrained_model.named_modules():\n",
    "    if isinstance(param, nn.Linear):\n",
    "        pretrained_layer_mapping_dict[name] = param\n",
    "\n",
    "\n",
    "# merged_model = deepcopy(pretrained_model)\n",
    "# merged_layer_mapping_dict = {}\n",
    "# for name, param in pretrained_model.named_modules():\n",
    "#     if isinstance(param, nn.Linear):\n",
    "#         merged_layer_mapping_dict[name] = param\n",
    "print('merging models...')\n",
    "# make a copy of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6fdbdaa16f4530bc5a6f57fb6f6d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6141fa5b109047bfb2b8f9f0f8c64310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f3a8ed441a484aaa3dab2d6999915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    top_ks = [0.01, 0.05, 0.1]\n",
    "    gammas = [1.0, 2.0, 3.0, 5.0]\n",
    "    \n",
    "    final_weight_dict = {}\n",
    "    for top_k in top_ks:\n",
    "        for gamma in gammas:\n",
    "            final_weight_dict[(top_k,gamma)] = {}\n",
    "\n",
    "        for name, param in tqdm(pretrained_layer_mapping_dict.items(), total=len(pretrained_layer_mapping_dict)):\n",
    "            base_importance = torch.softmax(pretrained_scale_dict[name],dim=0)\n",
    "            base_importance = base_importance / base_importance.max()\n",
    "            topk = torch.topk(base_importance, int(base_importance.numel() * top_k)).indices\n",
    "            important_clone = param.weight.data[:,topk].clone()\n",
    "            for gamma in gammas:\n",
    "                final_weight_dict[(top_k,gamma)][name] = param.weight.data.clone()\n",
    "            # final_weight_dict[name] = param.weight.data.clone()\n",
    "            for i in range(len(models_to_merge)):\n",
    "                scale_dict = scale_dicts[i]\n",
    "                layer_mapping_dict = layer_mapping_dicts[i]\n",
    "                scale = torch.softmax(scale_dict[name],dim=0)\n",
    "                scale = scale / scale.max()\n",
    "                delta = layer_mapping_dict[name].weight.data - pretrained_layer_mapping_dict[name].weight.data\n",
    "                delta = delta * scale[None, :]\n",
    "                \n",
    "                for gamma in gammas:\n",
    "                    final_weight_dict[(top_k,gamma)][name] += delta*gamma\n",
    "                # final_weight_dict[name] += delta*gamma\n",
    "                # print(torch.linalg.norm(delta))\n",
    "                # merged_layer_mapping_dict[name].weight.data += delta*gamma\n",
    "                \n",
    "            # merged_layer_mapping_dict[name].weight.data[:,topk] = important_clone\n",
    "            for gamma in gammas:\n",
    "                final_weight_dict[(top_k,gamma)][name][:,topk] = important_clone\n",
    "            # final_weight_dict[name][:,topk] = important_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n",
      "changed\n"
     ]
    }
   ],
   "source": [
    "for top_k in top_ks:\n",
    "    for gamma in gammas:\n",
    "        has_changed = False\n",
    "        for name, mod in pretrained_model.named_modules():\n",
    "            if isinstance(mod, nn.Linear):\n",
    "                if not has_changed:\n",
    "                    if not torch.allclose(mod.weight.data, final_weight_dict[(top_k,gamma)][name]):\n",
    "                        print(f'changed')\n",
    "                        has_changed = True\n",
    "                mod.weight.data = final_weight_dict[(top_k,gamma)][name]\n",
    "        pretrained_model.save_pretrained(f'./ActiveM_base/ActiveM_{top_k}_{gamma}')\n",
    "        pretrained_tokenizer.save_pretrained(f'./ActiveM_base/ActiveM_{top_k}_{gamma}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name, param_value in pretrained_model.named_parameters():\n",
    "    param_value.data.copy_(merged_model.state_dict()[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./ActiveM/tokenizer_config.json',\n",
       " './ActiveM/special_tokens_map.json',\n",
       " './ActiveM/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.save_pretrained('./ActiveM')\n",
    "pretrained_tokenizer.save_pretrained('./ActiveM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda76473663945f08b0781dde78bb861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b7026fb00b4b5c86891fd4d537613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_, model_ = load_model_and_tokenizer('./ActiveM',device='cpu')\n",
    "tokenizer, model = load_model_and_tokenizer(pretrained_model_name,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.self_attn.q_proj is equal\n",
      "model.layers.0.self_attn.k_proj is equal\n",
      "model.layers.0.self_attn.v_proj is equal\n",
      "model.layers.0.self_attn.o_proj is not equal\n",
      "model.layers.0.mlp.gate_proj is equal\n",
      "model.layers.0.mlp.up_proj is equal\n",
      "model.layers.0.mlp.down_proj is not equal\n",
      "model.layers.1.self_attn.q_proj is not equal\n",
      "model.layers.1.self_attn.k_proj is not equal\n",
      "model.layers.1.self_attn.v_proj is not equal\n",
      "model.layers.1.self_attn.o_proj is not equal\n",
      "model.layers.1.mlp.gate_proj is not equal\n",
      "model.layers.1.mlp.up_proj is not equal\n",
      "model.layers.1.mlp.down_proj is equal\n",
      "model.layers.2.self_attn.q_proj is not equal\n",
      "model.layers.2.self_attn.k_proj is not equal\n",
      "model.layers.2.self_attn.v_proj is not equal\n",
      "model.layers.2.self_attn.o_proj is not equal\n",
      "model.layers.2.mlp.gate_proj is not equal\n",
      "model.layers.2.mlp.up_proj is equal\n",
      "model.layers.2.mlp.down_proj is equal\n",
      "model.layers.3.self_attn.q_proj is not equal\n",
      "model.layers.3.self_attn.k_proj is not equal\n",
      "model.layers.3.self_attn.v_proj is not equal\n",
      "model.layers.3.self_attn.o_proj is not equal\n",
      "model.layers.3.mlp.gate_proj is equal\n",
      "model.layers.3.mlp.up_proj is equal\n",
      "model.layers.3.mlp.down_proj is equal\n",
      "model.layers.4.self_attn.q_proj is not equal\n",
      "model.layers.4.self_attn.k_proj is not equal\n",
      "model.layers.4.self_attn.v_proj is not equal\n",
      "model.layers.4.self_attn.o_proj is not equal\n",
      "model.layers.4.mlp.gate_proj is equal\n",
      "model.layers.4.mlp.up_proj is equal\n",
      "model.layers.4.mlp.down_proj is equal\n",
      "model.layers.5.self_attn.q_proj is equal\n",
      "model.layers.5.self_attn.k_proj is equal\n",
      "model.layers.5.self_attn.v_proj is equal\n",
      "model.layers.5.self_attn.o_proj is equal\n",
      "model.layers.5.mlp.gate_proj is equal\n",
      "model.layers.5.mlp.up_proj is equal\n",
      "model.layers.5.mlp.down_proj is equal\n",
      "model.layers.6.self_attn.q_proj is not equal\n",
      "model.layers.6.self_attn.k_proj is not equal\n",
      "model.layers.6.self_attn.v_proj is not equal\n",
      "model.layers.6.self_attn.o_proj is equal\n",
      "model.layers.6.mlp.gate_proj is equal\n",
      "model.layers.6.mlp.up_proj is equal\n",
      "model.layers.6.mlp.down_proj is equal\n",
      "model.layers.7.self_attn.q_proj is not equal\n",
      "model.layers.7.self_attn.k_proj is not equal\n",
      "model.layers.7.self_attn.v_proj is not equal\n",
      "model.layers.7.self_attn.o_proj is not equal\n",
      "model.layers.7.mlp.gate_proj is equal\n",
      "model.layers.7.mlp.up_proj is equal\n",
      "model.layers.7.mlp.down_proj is equal\n",
      "model.layers.8.self_attn.q_proj is not equal\n",
      "model.layers.8.self_attn.k_proj is not equal\n",
      "model.layers.8.self_attn.v_proj is not equal\n",
      "model.layers.8.self_attn.o_proj is equal\n",
      "model.layers.8.mlp.gate_proj is equal\n",
      "model.layers.8.mlp.up_proj is equal\n",
      "model.layers.8.mlp.down_proj is not equal\n",
      "model.layers.9.self_attn.q_proj is not equal\n",
      "model.layers.9.self_attn.k_proj is not equal\n",
      "model.layers.9.self_attn.v_proj is not equal\n",
      "model.layers.9.self_attn.o_proj is equal\n",
      "model.layers.9.mlp.gate_proj is equal\n",
      "model.layers.9.mlp.up_proj is equal\n",
      "model.layers.9.mlp.down_proj is equal\n",
      "model.layers.10.self_attn.q_proj is not equal\n",
      "model.layers.10.self_attn.k_proj is not equal\n",
      "model.layers.10.self_attn.v_proj is not equal\n",
      "model.layers.10.self_attn.o_proj is equal\n",
      "model.layers.10.mlp.gate_proj is equal\n",
      "model.layers.10.mlp.up_proj is equal\n",
      "model.layers.10.mlp.down_proj is equal\n",
      "model.layers.11.self_attn.q_proj is not equal\n",
      "model.layers.11.self_attn.k_proj is not equal\n",
      "model.layers.11.self_attn.v_proj is not equal\n",
      "model.layers.11.self_attn.o_proj is equal\n",
      "model.layers.11.mlp.gate_proj is equal\n",
      "model.layers.11.mlp.up_proj is equal\n",
      "model.layers.11.mlp.down_proj is equal\n",
      "model.layers.12.self_attn.q_proj is not equal\n",
      "model.layers.12.self_attn.k_proj is not equal\n",
      "model.layers.12.self_attn.v_proj is not equal\n",
      "model.layers.12.self_attn.o_proj is equal\n",
      "model.layers.12.mlp.gate_proj is equal\n",
      "model.layers.12.mlp.up_proj is equal\n",
      "model.layers.12.mlp.down_proj is equal\n",
      "model.layers.13.self_attn.q_proj is equal\n",
      "model.layers.13.self_attn.k_proj is equal\n",
      "model.layers.13.self_attn.v_proj is equal\n",
      "model.layers.13.self_attn.o_proj is equal\n",
      "model.layers.13.mlp.gate_proj is equal\n",
      "model.layers.13.mlp.up_proj is equal\n",
      "model.layers.13.mlp.down_proj is equal\n",
      "model.layers.14.self_attn.q_proj is equal\n",
      "model.layers.14.self_attn.k_proj is equal\n",
      "model.layers.14.self_attn.v_proj is equal\n",
      "model.layers.14.self_attn.o_proj is equal\n",
      "model.layers.14.mlp.gate_proj is equal\n",
      "model.layers.14.mlp.up_proj is equal\n",
      "model.layers.14.mlp.down_proj is equal\n",
      "model.layers.15.self_attn.q_proj is not equal\n",
      "model.layers.15.self_attn.k_proj is not equal\n",
      "model.layers.15.self_attn.v_proj is not equal\n",
      "model.layers.15.self_attn.o_proj is equal\n",
      "model.layers.15.mlp.gate_proj is equal\n",
      "model.layers.15.mlp.up_proj is equal\n",
      "model.layers.15.mlp.down_proj is not equal\n",
      "model.layers.16.self_attn.q_proj is not equal\n",
      "model.layers.16.self_attn.k_proj is not equal\n",
      "model.layers.16.self_attn.v_proj is not equal\n",
      "model.layers.16.self_attn.o_proj is equal\n",
      "model.layers.16.mlp.gate_proj is equal\n",
      "model.layers.16.mlp.up_proj is equal\n",
      "model.layers.16.mlp.down_proj is equal\n",
      "model.layers.17.self_attn.q_proj is not equal\n",
      "model.layers.17.self_attn.k_proj is not equal\n",
      "model.layers.17.self_attn.v_proj is not equal\n",
      "model.layers.17.self_attn.o_proj is equal\n",
      "model.layers.17.mlp.gate_proj is equal\n",
      "model.layers.17.mlp.up_proj is equal\n",
      "model.layers.17.mlp.down_proj is equal\n",
      "model.layers.18.self_attn.q_proj is not equal\n",
      "model.layers.18.self_attn.k_proj is not equal\n",
      "model.layers.18.self_attn.v_proj is not equal\n",
      "model.layers.18.self_attn.o_proj is equal\n",
      "model.layers.18.mlp.gate_proj is equal\n",
      "model.layers.18.mlp.up_proj is equal\n",
      "model.layers.18.mlp.down_proj is equal\n",
      "model.layers.19.self_attn.q_proj is not equal\n",
      "model.layers.19.self_attn.k_proj is not equal\n",
      "model.layers.19.self_attn.v_proj is not equal\n",
      "model.layers.19.self_attn.o_proj is equal\n",
      "model.layers.19.mlp.gate_proj is equal\n",
      "model.layers.19.mlp.up_proj is equal\n",
      "model.layers.19.mlp.down_proj is equal\n",
      "model.layers.20.self_attn.q_proj is not equal\n",
      "model.layers.20.self_attn.k_proj is not equal\n",
      "model.layers.20.self_attn.v_proj is not equal\n",
      "model.layers.20.self_attn.o_proj is equal\n",
      "model.layers.20.mlp.gate_proj is equal\n",
      "model.layers.20.mlp.up_proj is equal\n",
      "model.layers.20.mlp.down_proj is equal\n",
      "model.layers.21.self_attn.q_proj is not equal\n",
      "model.layers.21.self_attn.k_proj is not equal\n",
      "model.layers.21.self_attn.v_proj is not equal\n",
      "model.layers.21.self_attn.o_proj is equal\n",
      "model.layers.21.mlp.gate_proj is equal\n",
      "model.layers.21.mlp.up_proj is equal\n",
      "model.layers.21.mlp.down_proj is equal\n",
      "model.layers.22.self_attn.q_proj is not equal\n",
      "model.layers.22.self_attn.k_proj is not equal\n",
      "model.layers.22.self_attn.v_proj is not equal\n",
      "model.layers.22.self_attn.o_proj is not equal\n",
      "model.layers.22.mlp.gate_proj is equal\n",
      "model.layers.22.mlp.up_proj is equal\n",
      "model.layers.22.mlp.down_proj is equal\n",
      "model.layers.23.self_attn.q_proj is not equal\n",
      "model.layers.23.self_attn.k_proj is not equal\n",
      "model.layers.23.self_attn.v_proj is not equal\n",
      "model.layers.23.self_attn.o_proj is equal\n",
      "model.layers.23.mlp.gate_proj is equal\n",
      "model.layers.23.mlp.up_proj is equal\n",
      "model.layers.23.mlp.down_proj is equal\n",
      "model.layers.24.self_attn.q_proj is not equal\n",
      "model.layers.24.self_attn.k_proj is not equal\n",
      "model.layers.24.self_attn.v_proj is not equal\n",
      "model.layers.24.self_attn.o_proj is equal\n",
      "model.layers.24.mlp.gate_proj is equal\n",
      "model.layers.24.mlp.up_proj is equal\n",
      "model.layers.24.mlp.down_proj is equal\n",
      "model.layers.25.self_attn.q_proj is not equal\n",
      "model.layers.25.self_attn.k_proj is not equal\n",
      "model.layers.25.self_attn.v_proj is not equal\n",
      "model.layers.25.self_attn.o_proj is equal\n",
      "model.layers.25.mlp.gate_proj is equal\n",
      "model.layers.25.mlp.up_proj is equal\n",
      "model.layers.25.mlp.down_proj is equal\n",
      "model.layers.26.self_attn.q_proj is not equal\n",
      "model.layers.26.self_attn.k_proj is not equal\n",
      "model.layers.26.self_attn.v_proj is not equal\n",
      "model.layers.26.self_attn.o_proj is equal\n",
      "model.layers.26.mlp.gate_proj is equal\n",
      "model.layers.26.mlp.up_proj is equal\n",
      "model.layers.26.mlp.down_proj is equal\n",
      "model.layers.27.self_attn.q_proj is not equal\n",
      "model.layers.27.self_attn.k_proj is not equal\n",
      "model.layers.27.self_attn.v_proj is not equal\n",
      "model.layers.27.self_attn.o_proj is equal\n",
      "model.layers.27.mlp.gate_proj is equal\n",
      "model.layers.27.mlp.up_proj is equal\n",
      "model.layers.27.mlp.down_proj is equal\n",
      "model.layers.28.self_attn.q_proj is not equal\n",
      "model.layers.28.self_attn.k_proj is not equal\n",
      "model.layers.28.self_attn.v_proj is not equal\n",
      "model.layers.28.self_attn.o_proj is equal\n",
      "model.layers.28.mlp.gate_proj is equal\n",
      "model.layers.28.mlp.up_proj is equal\n",
      "model.layers.28.mlp.down_proj is equal\n",
      "model.layers.29.self_attn.q_proj is equal\n",
      "model.layers.29.self_attn.k_proj is equal\n",
      "model.layers.29.self_attn.v_proj is equal\n",
      "model.layers.29.self_attn.o_proj is equal\n",
      "model.layers.29.mlp.gate_proj is equal\n",
      "model.layers.29.mlp.up_proj is equal\n",
      "model.layers.29.mlp.down_proj is equal\n",
      "model.layers.30.self_attn.q_proj is equal\n",
      "model.layers.30.self_attn.k_proj is equal\n",
      "model.layers.30.self_attn.v_proj is equal\n",
      "model.layers.30.self_attn.o_proj is equal\n",
      "model.layers.30.mlp.gate_proj is equal\n",
      "model.layers.30.mlp.up_proj is equal\n",
      "model.layers.30.mlp.down_proj is equal\n",
      "model.layers.31.self_attn.q_proj is equal\n",
      "model.layers.31.self_attn.k_proj is equal\n",
      "model.layers.31.self_attn.v_proj is equal\n",
      "model.layers.31.self_attn.o_proj is not equal\n",
      "model.layers.31.mlp.gate_proj is equal\n",
      "model.layers.31.mlp.up_proj is equal\n",
      "model.layers.31.mlp.down_proj is not equal\n",
      "lm_head is not equal\n"
     ]
    }
   ],
   "source": [
    "# loop through the model and compare the weights\n",
    "import torch\n",
    "lin_dict = {}\n",
    "for name, param in model.named_modules():\n",
    "    if isinstance(param, nn.Linear):\n",
    "        lin_dict[name] = param.weight\n",
    "for name, param in model_.named_modules():\n",
    "    if isinstance(param, nn.Linear):\n",
    "        if torch.allclose(param.weight, lin_dict[name]):\n",
    "            print(f'{name} is equal')\n",
    "        else:\n",
    "            print(f'{name} is not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5893df18447adbb4ae2c3fb34a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122c62d647b248af93d27e88c6ae8669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned could not be loaded.\n",
      "Reason: Unrecognized model in ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5465fff7e9c54d63b0e228f06cf7fee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47044d635d5b47faac1bfad7701d927a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cd4c200f394feb85fd37ae1786312a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a77e255734e12aa0e06dd58c8171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yitzshapiro/brochat-meta-llama-31-8b could not be loaded.\n",
      "Reason: yitzshapiro/brochat-meta-llama-31-8b does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5c5ac71044565ac6dd61a4489cfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f36fa417144a5daa82b9578fd2a70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a53c123f76d47ac8c669fa7dd9bc944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cb96e31def4be5b1290677abca7dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rishitdass/Youtube-Video-Summarizer could not be loaded.\n",
      "Reason: Unrecognized model in rishitdass/Youtube-Video-Summarizer. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ab5948aa674e3e9caafd8e7c3d61fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting calibration features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738b885be294123983dbe84eadbdedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cd6dbf83194affac5d85285b376492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7adcd1be9a41a493e44991723a5289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7573 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ace5ef7375a4e1bb8bd281b5c98f58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9994619a27004a99bb2e0c8e75238b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e031a0737bea4b3bb6684b33febdae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c259d8e67b48ac9c0d51cde8994140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b294183f949748d7ab1e2ba7e5729e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4be4655d034f0b837e72182700e6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9f8d97853743f2bfc9a290250deee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7573 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da25e58bb7d547099b09ea9619ec1e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Split into 124 blocks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6ed9e85d8849d7bdc184820199d05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f58b40f0ad418aaa5b2de58cca2394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinetuned_model_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/VLLM/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP_Mixture/MergeModels/ActivationMerging/_utils.py:138\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(finetuned_model_names, pretrained_model_name, topk, scaling, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m base_importance \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(pretrained_scale_dict[name],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    137\u001b[0m base_importance \u001b[38;5;241m=\u001b[39m base_importance \u001b[38;5;241m/\u001b[39m base_importance\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m--> 138\u001b[0m topk \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(base_importance, \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_importance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mindices\n\u001b[1;32m    139\u001b[0m important_clone \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mweight[:,topk]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models_to_merge)):\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "model, tokenizer = activation_merge(finetuned_model_names, pretrained_model_name, topk=0.05, scaling=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
