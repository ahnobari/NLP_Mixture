{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('checkpoints.yml', 'r') as file:\n",
    "    checkpoints = yaml.safe_load(file)\n",
    "\n",
    "pretrained_model_name = checkpoints['Instruct'][0]['HF_Repo']\n",
    "finetuned_model_names = [item[next(iter(item))][0]['HF_Repo'] for item in checkpoints['Checkpoints']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21a5a0435724d3391d0bdd599014019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089c1207017f4086a42eb0b880b65e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned could not be loaded.\n",
      "Reason: Unrecognized model in ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240375ec9f248b9a9cf032cf693bee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414e28bd3d4947b097e3b50cd4e0fb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d154903870a440d9ae2591efe25c4d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b18fcab9834997ad8e0bf5fcd81fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yitzshapiro/brochat-meta-llama-31-8b could not be loaded.\n",
      "Reason: yitzshapiro/brochat-meta-llama-31-8b does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7253516722c4c2e90edac6fe1db459a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09be48cf3e684a95926fc6a8358cd93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438da36e0bd645c6afcf8743ff0a852e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8121aaac86409cab74c00309f921b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rishitdass/Youtube-Video-Summarizer could not be loaded.\n",
      "Reason: Unrecognized model in rishitdass/Youtube-Video-Summarizer. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e709a8cb79004b9b88dc4898dcd8f4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817344882d34f928d3f67960ebd5574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13228ef2457846828f4a984678fb9d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned could not be loaded.\n",
      "Reason: Unrecognized model in ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32683241e05d46e9a93d224d854431ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddc8d73d59e4d80a776caa39ffc2b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f391488419014b43b59d379d03393adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dc8039d9f845a4b5699e5c572ad2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yitzshapiro/brochat-meta-llama-31-8b could not be loaded.\n",
      "Reason: yitzshapiro/brochat-meta-llama-31-8b does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb391781c0b14387910053e81edd2c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867e76fd5ca74cdcb405a979650075d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad087584f1d842918a1043cecf5ca80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749ee46a71fb46aea1c19ad72d63ce0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rishitdass/Youtube-Video-Summarizer could not be loaded.\n",
      "Reason: Unrecognized model in rishitdass/Youtube-Video-Summarizer. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e764fc0f77b840dcb6b8f3336491e789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281fcfd0a6e0495d953d4bf98f5a0273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee534183f2ae4b46a6e68e7c84d71bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned could not be loaded.\n",
      "Reason: Unrecognized model in ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32d240c8a1d4e049b784e889a26a52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6c0ad5375444e8876609b077042307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f208837f4425403aae2e243fc8540fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6a9acdea214db19273ba3b406bae26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yitzshapiro/brochat-meta-llama-31-8b could not be loaded.\n",
      "Reason: yitzshapiro/brochat-meta-llama-31-8b does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133542b9d1a340f1a92729cbf9c14ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ca277cb6c0408c9034078ab11ca19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f2e60a81164cbdaaeac7eea8d68165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a31cb0fab594270962f77777d18e02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rishitdass/Youtube-Video-Summarizer could not be loaded.\n",
      "Reason: Unrecognized model in rishitdass/Youtube-Video-Summarizer. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b8d048abcb4e50970f82c4d3b95599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [13:36<00:00,  2.81s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959ef0975e004c99ab838ebb485ee94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9806866fb8154a399a8492f6b25426d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned could not be loaded.\n",
      "Reason: Unrecognized model in ahmeterdempmk/Llama-3.1-8B-Fast-Food-Based-Tuned. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671e31b15db64aaeb5b24f774a4e7cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b775154c114abf8850dda32cf179b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623928b604ff46d88da3749ff35d34e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee73f85c5966483a8e6bd0ac85d38d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yitzshapiro/brochat-meta-llama-31-8b could not be loaded.\n",
      "Reason: yitzshapiro/brochat-meta-llama-31-8b does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fa3605ec494ba1a6be90497dec3b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb00c68f06404e7ea9bbdbaeeabfbb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a3ec76c1d24e82944471f66cb49e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f64390a20d48958feb86c59a834b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rishitdass/Youtube-Video-Summarizer could not be loaded.\n",
      "Reason: Unrecognized model in rishitdass/Youtube-Video-Summarizer. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697ed91c94e446969394da07d3ee57d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [01:03<00:00,  4.61it/s]\n",
      "100%|██████████| 291/291 [01:06<00:00,  4.35it/s]\n",
      "100%|██████████| 291/291 [00:54<00:00,  5.37it/s]\n",
      "100%|██████████| 291/291 [00:55<00:00,  5.26it/s]\n",
      "100%|██████████| 291/291 [00:56<00:00,  5.14it/s]\n",
      "100%|██████████| 291/291 [00:55<00:00,  5.22it/s]\n",
      "100%|██████████| 291/291 [00:58<00:00,  4.97it/s]\n",
      "100%|██████████| 291/291 [00:55<00:00,  5.28it/s]\n",
      "100%|██████████| 291/291 [00:53<00:00,  5.39it/s]\n",
      "100%|██████████| 291/291 [00:53<00:00,  5.42it/s]\n",
      "100%|██████████| 291/291 [00:53<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from MergeModels import *\n",
    "\n",
    "choices=[\"average_merging\", \"task_arithmetic\", \"ties_merging\", \"widen_merging\", \"mask_merging\"]\n",
    "for merging_method in [\"average_merging\", \"task_arithmetic\", \"ties_merging\", \"mask_merging\"]:\n",
    "    model, tokenizer = merge(finetuned_model_names, pretrained_model_name, merging_method)\n",
    "    save_directory = './'+ merging_method\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./widen/tokenizer_config.json',\n",
       " './widen/special_tokens_map.json',\n",
       " './widen/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = './widen'\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-07 16:16:55 config.py:1861] Downcasting torch.float32 to torch.float16.\n",
      "INFO 12-07 16:16:58 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 12-07 16:16:58 config.py:1020] Defaulting to use mp for distributed inference\n",
      "WARNING 12-07 16:16:58 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 12-07 16:16:58 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 12-07 16:16:58 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='./widen', speculative_config=None, tokenizer='./widen', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=39000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=./widen, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "WARNING 12-07 16:16:58 multiproc_gpu_executor.py:56] Reducing Torch parallelism from 36 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 12-07 16:16:58 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "INFO 12-07 16:16:59 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 12-07 16:16:59 utils.py:961] Found nccl from library libnccl.so.2\n",
      "INFO 12-07 16:16:59 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 utils.py:961] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 12-07 16:16:59 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/amin/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "WARNING 12-07 16:16:59 custom_all_reduce.py:143] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/amin/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m WARNING 12-07 16:16:59 custom_all_reduce.py:143] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 12-07 16:16:59 shm_broadcast.py:236] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7e0ff9a04070>, local_subscribe_port=59305, remote_subscribe_port=None)\n",
      "INFO 12-07 16:16:59 model_runner.py:1072] Starting to load model ./widen...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:16:59 model_runner.py:1072] Starting to load model ./widen...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b661f0fc74c44fdbf71bef2c9565ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:17:05 model_runner.py:1077] Loading model weights took 7.5122 GB\n",
      "INFO 12-07 16:17:05 model_runner.py:1077] Loading model weights took 7.5122 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:17:05 worker.py:232] Memory profiling results: total_gpu_memory=23.53GiB initial_memory_usage=8.24GiB peak_torch_memory=7.56GiB memory_usage_post_profile=8.32GiB non_torch_memory=0.80GiB kv_cache_size=12.82GiB gpu_memory_utilization=0.90\n",
      "INFO 12-07 16:17:06 worker.py:232] Memory profiling results: total_gpu_memory=23.54GiB initial_memory_usage=8.12GiB peak_torch_memory=8.69GiB memory_usage_post_profile=8.20GiB non_torch_memory=0.68GiB kv_cache_size=11.82GiB gpu_memory_utilization=0.90\n",
      "INFO 12-07 16:17:06 distributed_gpu_executor.py:57] # GPU blocks: 12103, # CPU blocks: 4096\n",
      "INFO 12-07 16:17:06 distributed_gpu_executor.py:61] Maximum concurrency for 39000 tokens per request: 4.97x\n",
      "INFO 12-07 16:17:07 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-07 16:17:07 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:17:07 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:17:07 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=277331)\u001b[0;0m INFO 12-07 16:17:24 model_runner.py:1518] Graph capturing finished in 17 secs, took 0.43 GiB\n",
      "INFO 12-07 16:17:24 model_runner.py:1518] Graph capturing finished in 17 secs, took 0.43 GiB\n"
     ]
    }
   ],
   "source": [
    "from EvalUtils import * \n",
    "\n",
    "model = load_model(\"./widen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evalplus[vllm]\n",
      "  Downloading evalplus-0.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting wget>=3.2 (from evalplus[vllm])\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tempdir>=0.7.1 (from evalplus[vllm])\n",
      "  Downloading tempdir-0.7.1.tar.gz (5.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting multipledispatch>=0.6.0 (from evalplus[vllm])\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting appdirs>=1.4.4 (from evalplus[vllm])\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.56.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (4.67.1)\n",
      "Collecting termcolor>=2.0.0 (from evalplus[vllm])\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting fire>=0.6.0 (from evalplus[vllm])\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openai>=1.11.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (1.56.0)\n",
      "Collecting tree-sitter>=0.22.0 (from evalplus[vllm])\n",
      "  Downloading tree_sitter-0.23.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
      "Collecting tree-sitter-python>=0.21.0 (from evalplus[vllm])\n",
      "  Downloading tree_sitter_python-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting rich>=12.3.0 (from evalplus[vllm])\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers>=4.43.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (4.46.3)\n",
      "Collecting stop-sequencer>=1.2.3 (from evalplus[vllm])\n",
      "  Downloading stop-sequencer-1.2.3.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anthropic>=0.34.1 (from evalplus[vllm])\n",
      "  Downloading anthropic-0.40.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting google-generativeai>=0.7.2 (from evalplus[vllm])\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (3.1.0)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (6.1.0)\n",
      "Requirement already satisfied: vllm>=0.5.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from evalplus[vllm]) (0.6.4.post1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (2.10.2)\n",
      "Requirement already satisfied: sniffio in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anthropic>=0.34.1->evalplus[vllm]) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->evalplus[vllm]) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (3.11.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (0.26.3)\n",
      "Requirement already satisfied: packaging in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from datasets>=2.21.0->evalplus[vllm]) (6.0.2)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from google-generativeai>=0.7.2->evalplus[vllm]) (5.29.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.3.0->evalplus[vllm])\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from rich>=12.3.0->evalplus[vllm]) (2.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from transformers>=4.43.0->evalplus[vllm]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from transformers>=4.43.0->evalplus[vllm]) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from transformers>=4.43.0->evalplus[vllm]) (0.4.5)\n",
      "Requirement already satisfied: sentencepiece in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.2.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (9.0.0)\n",
      "Requirement already satisfied: uvicorn[standard] in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.32.1)\n",
      "Requirement already satisfied: pillow in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.21.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (7.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.7.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.10.9)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.0.46)\n",
      "Requirement already satisfied: partial-json-parser in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.2.1.1.post4)\n",
      "Requirement already satisfied: pyzmq in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (26.2.0)\n",
      "Requirement already satisfied: msgspec in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.18.6)\n",
      "Requirement already satisfied: gguf==0.10.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (8.5.0)\n",
      "Requirement already satisfied: mistral-common>=1.5.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from mistral-common[opencv]>=1.5.0->vllm>=0.5.1->evalplus[vllm]) (1.5.1)\n",
      "Requirement already satisfied: einops in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.8.0)\n",
      "Requirement already satisfied: compressed-tensors==0.8.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.8.0)\n",
      "Requirement already satisfied: ray>=2.9 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (2.39.0)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (12.560.30)\n",
      "Requirement already satisfied: torch==2.5.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (2.5.1)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.0.28.post3)\n",
      "Requirement already satisfied: six>=1.16.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (75.6.0)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from vllm>=0.5.1->evalplus[vllm]) (0.115.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from torch==2.5.1->vllm>=0.5.1->evalplus[vllm]) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from torch==2.5.1->vllm>=0.5.1->evalplus[vllm]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from torch==2.5.1->vllm>=0.5.1->evalplus[vllm]) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->vllm>=0.5.1->evalplus[vllm]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic>=0.34.1->evalplus[vllm]) (3.10)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm>=0.5.1->evalplus[vllm]) (0.41.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->evalplus[vllm]) (1.18.3)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: certifi in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic>=0.34.1->evalplus[vllm]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic>=0.34.1->evalplus[vllm]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic>=0.34.1->evalplus[vllm]) (0.14.0)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm>=0.5.1->evalplus[vllm]) (0.3.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.3.0->evalplus[vllm])\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm>=0.5.1->evalplus[vllm]) (4.23.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from mistral-common[opencv]>=1.5.0->vllm>=0.5.1->evalplus[vllm]) (4.10.0.84)\n",
      "Requirement already satisfied: lark in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (3.1.0)\n",
      "Requirement already satisfied: diskcache in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (5.6.3)\n",
      "Requirement already satisfied: numba in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (0.60.0)\n",
      "Requirement already satisfied: referencing in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (0.35.1)\n",
      "Requirement already satisfied: pycountry in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (2.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic>=0.34.1->evalplus[vllm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic>=0.34.1->evalplus[vllm]) (2.27.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from ray>=2.9->vllm>=0.5.1->evalplus[vllm]) (8.1.7)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from ray>=2.9->vllm>=0.5.1->evalplus[vllm]) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->evalplus[vllm]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->evalplus[vllm]) (2.2.3)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from importlib-metadata->vllm>=0.5.1->evalplus[vllm]) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->evalplus[vllm]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->evalplus[vllm]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->evalplus[vllm]) (2024.2)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from uvicorn[standard]->vllm>=0.5.1->evalplus[vllm]) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from uvicorn[standard]->vllm>=0.5.1->evalplus[vllm]) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from uvicorn[standard]->vllm>=0.5.1->evalplus[vllm]) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from uvicorn[standard]->vllm>=0.5.1->evalplus[vllm]) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from uvicorn[standard]->vllm>=0.5.1->evalplus[vllm]) (14.1)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading grpcio-1.68.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.7.2->evalplus[vllm]) (3.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm>=0.5.1->evalplus[vllm]) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm>=0.5.1->evalplus[vllm]) (0.21.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.7.2->evalplus[vllm])\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from jinja2->torch==2.5.1->vllm>=0.5.1->evalplus[vllm]) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/amin/miniforge3/envs/NLP/lib/python3.12/site-packages (from numba->outlines<0.1,>=0.0.43->vllm>=0.5.1->evalplus[vllm]) (0.43.0)\n",
      "Downloading anthropic-0.40.0-py3-none-any.whl (199 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tree_sitter-0.23.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (571 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.2/571.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tree_sitter_python-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
      "Downloading evalplus-0.3.1-py3-none-any.whl (68 kB)\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.68.1-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: fire, stop-sequencer, tempdir, wget\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=fe8a3de7fa514c4ad2955134b3c4ac2ef02bc635bc67f371ea8286b75b319d36\n",
      "  Stored in directory: /home/amin/.cache/pip/wheels/9e/5b/45/29f72e55d87a29426b04b3cfdf20325c079eb97ab74f59017d\n",
      "  Building wheel for stop-sequencer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stop-sequencer: filename=stop_sequencer-1.2.3-py3-none-any.whl size=4870 sha256=98436300ca2ca3e8a3293a87bbc1e67d6a87fcfc1e4ace8a9ac56984c33601fd\n",
      "  Stored in directory: /home/amin/.cache/pip/wheels/b4/a3/12/0c6a6541ed0eafd69c075930baea3a103ae49c7d03de988290\n",
      "  Building wheel for tempdir (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tempdir: filename=tempdir-0.7.1-py3-none-any.whl size=2195 sha256=e0422469b6c8014eb7c6b65809a065cccd732578c255a1effcb23c593204250e\n",
      "  Stored in directory: /home/amin/.cache/pip/wheels/1e/14/6b/dedd96c73357be1d37d03b56a8bcfc5425df347e05115ac18c\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=33364f1c8052d420f2c79811907d8402d9a33731e380a1fcc94f5db09109e1ad\n",
      "  Stored in directory: /home/amin/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built fire stop-sequencer tempdir wget\n",
      "Installing collected packages: wget, tempdir, multipledispatch, appdirs, uritemplate, tree-sitter-python, tree-sitter, termcolor, pyasn1, proto-plus, mdurl, httplib2, grpcio, googleapis-common-protos, cachetools, rsa, pyasn1-modules, markdown-it-py, grpcio-status, fire, rich, google-auth, anthropic, google-auth-httplib2, google-api-core, stop-sequencer, google-api-python-client, google-ai-generativelanguage, google-generativeai, evalplus\n",
      "Successfully installed anthropic-0.40.0 appdirs-1.4.4 cachetools-5.5.0 evalplus-0.3.1 fire-0.7.0 google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.154.0 google-auth-2.36.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.1 grpcio-status-1.68.1 httplib2-0.22.0 markdown-it-py-3.0.0 mdurl-0.1.2 multipledispatch-1.0.0 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rich-13.9.4 rsa-4.9 stop-sequencer-1.2.3 tempdir-0.7.1 termcolor-2.5.0 tree-sitter-0.23.2 tree-sitter-python-0.23.5 uritemplate-4.1.1 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install evalplus[vllm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
