{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 18,
        "acc": 28.7,
        "type_acc": {
            "Algebra": 43.5,
            "Counting & Probability": 23.0,
            "Geometry": 24.8,
            "Intermediate Algebra": 11.0,
            "Number Theory": 17.8,
            "Prealgebra": 48.2,
            "Precalculus": 13.9
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 0,
        "acc": 70.0
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 0,
        "acc": 29.4
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 1,
        "empty_samples": 1,
        "acc": 33.4
    },
    "mbpp": {
        "base": {
            "pass@1": 0.6375661375661376
        },
        "+": {
            "pass@1": 0.5211640211640212
        }
    },
    "mmlu": {
        "abstract_algebra": 0.36,
        "anatomy": 0.6,
        "astronomy": 0.7171052631578947,
        "business_ethics": 0.67,
        "clinical_knowledge": 0.7094339622641509,
        "college_biology": 0.7569444444444444,
        "college_chemistry": 0.45,
        "college_computer_science": 0.54,
        "college_mathematics": 0.34,
        "college_medicine": 0.6647398843930635,
        "college_physics": 0.38235294117647056,
        "computer_security": 0.8,
        "conceptual_physics": 0.5574468085106383,
        "econometrics": 0.4298245614035088,
        "electrical_engineering": 0.6068965517241379,
        "elementary_mathematics": 0.3835978835978836,
        "formal_logic": 0.5317460317460317,
        "global_facts": 0.27,
        "high_school_biology": 0.7774193548387097,
        "high_school_chemistry": 0.5320197044334976,
        "high_school_computer_science": 0.66,
        "high_school_european_history": 0.7818181818181819,
        "high_school_geography": 0.7929292929292929,
        "high_school_government_and_politics": 0.8860103626943006,
        "high_school_macroeconomics": 0.6128205128205129,
        "high_school_mathematics": 0.34814814814814815,
        "high_school_microeconomics": 0.7184873949579832,
        "high_school_physics": 0.3509933774834437,
        "high_school_psychology": 0.8366972477064221,
        "high_school_statistics": 0.5277777777777778,
        "high_school_us_history": 0.7892156862745098,
        "high_school_world_history": 0.8312236286919831,
        "human_aging": 0.7085201793721974,
        "human_sexuality": 0.7557251908396947,
        "international_law": 0.7933884297520661,
        "jurisprudence": 0.7222222222222222,
        "logical_fallacies": 0.7852760736196319,
        "machine_learning": 0.5,
        "management": 0.8058252427184466,
        "marketing": 0.8803418803418803,
        "medical_genetics": 0.8,
        "miscellaneous": 0.8045977011494253,
        "moral_disputes": 0.6907514450867052,
        "moral_scenarios": 0.423463687150838,
        "nutrition": 0.7450980392156863,
        "philosophy": 0.6881028938906752,
        "prehistory": 0.7037037037037037,
        "professional_accounting": 0.4432624113475177,
        "professional_law": 0.4765319426336376,
        "professional_medicine": 0.6764705882352942,
        "professional_psychology": 0.6928104575163399,
        "public_relations": 0.6727272727272727,
        "security_studies": 0.7224489795918367,
        "sociology": 0.8706467661691543,
        "us_foreign_policy": 0.85,
        "virology": 0.5421686746987951,
        "world_religions": 0.8187134502923976,
        "overall": 0.6358068651189289
    }
}