{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 54,
        "acc": 25.9,
        "type_acc": {
            "Algebra": 38.9,
            "Counting & Probability": 16.2,
            "Geometry": 21.1,
            "Intermediate Algebra": 8.9,
            "Number Theory": 20.9,
            "Prealgebra": 44.4,
            "Precalculus": 14.1
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 1,
        "acc": 68.7
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 7,
        "acc": 27.4
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 1,
        "acc": 36.5
    },
    "mbpp": {
        "base": {
            "pass@1": 0.6904761904761905
        },
        "+": {
            "pass@1": 0.5714285714285714
        }
    },
    "mmlu": {
        "abstract_algebra": 0.29,
        "anatomy": 0.6148148148148148,
        "astronomy": 0.6973684210526315,
        "business_ethics": 0.64,
        "clinical_knowledge": 0.7320754716981132,
        "college_biology": 0.7291666666666666,
        "college_chemistry": 0.44,
        "college_computer_science": 0.5,
        "college_mathematics": 0.37,
        "college_medicine": 0.6242774566473989,
        "college_physics": 0.45098039215686275,
        "computer_security": 0.83,
        "conceptual_physics": 0.502127659574468,
        "econometrics": 0.4649122807017544,
        "electrical_engineering": 0.6344827586206897,
        "elementary_mathematics": 0.4021164021164021,
        "formal_logic": 0.5079365079365079,
        "global_facts": 0.35,
        "high_school_biology": 0.7838709677419354,
        "high_school_chemistry": 0.5172413793103449,
        "high_school_computer_science": 0.66,
        "high_school_european_history": 0.7818181818181819,
        "high_school_geography": 0.7929292929292929,
        "high_school_government_and_politics": 0.8601036269430051,
        "high_school_macroeconomics": 0.6307692307692307,
        "high_school_mathematics": 0.3037037037037037,
        "high_school_microeconomics": 0.7016806722689075,
        "high_school_physics": 0.3708609271523179,
        "high_school_psychology": 0.8605504587155963,
        "high_school_statistics": 0.4722222222222222,
        "high_school_us_history": 0.8333333333333334,
        "high_school_world_history": 0.8016877637130801,
        "human_aging": 0.7085201793721974,
        "human_sexuality": 0.7709923664122137,
        "international_law": 0.8181818181818182,
        "jurisprudence": 0.7407407407407407,
        "logical_fallacies": 0.7668711656441718,
        "machine_learning": 0.5,
        "management": 0.7961165048543689,
        "marketing": 0.8547008547008547,
        "medical_genetics": 0.79,
        "miscellaneous": 0.8058748403575989,
        "moral_disputes": 0.7196531791907514,
        "moral_scenarios": 0.4134078212290503,
        "nutrition": 0.738562091503268,
        "philosophy": 0.7459807073954984,
        "prehistory": 0.7253086419753086,
        "professional_accounting": 0.46808510638297873,
        "professional_law": 0.47979139504563234,
        "professional_medicine": 0.6580882352941176,
        "professional_psychology": 0.7254901960784313,
        "public_relations": 0.7181818181818181,
        "security_studies": 0.7346938775510204,
        "sociology": 0.8656716417910447,
        "us_foreign_policy": 0.87,
        "virology": 0.5481927710843374,
        "world_religions": 0.8070175438596491,
        "overall": 0.6390827517447657
    }
}