{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 7,
        "acc": 47.6,
        "type_acc": {
            "Algebra": 67.1,
            "Counting & Probability": 40.3,
            "Geometry": 36.7,
            "Intermediate Algebra": 27.8,
            "Number Theory": 36.7,
            "Prealgebra": 67.5,
            "Precalculus": 33.2
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 4,
        "empty_samples": 0,
        "acc": 61.6
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 0,
        "acc": 45.8
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 1,
        "empty_samples": 3,
        "acc": 30.6
    },
    "mbpp": {
        "base": {
            "pass@1": 0.6984126984126984
        },
        "+": {
            "pass@1": 0.5846560846560847
        }
    },
    "mmlu": {
        "abstract_algebra": 0.35,
        "anatomy": 0.6444444444444445,
        "astronomy": 0.7236842105263158,
        "business_ethics": 0.73,
        "clinical_knowledge": 0.7320754716981132,
        "college_biology": 0.7847222222222222,
        "college_chemistry": 0.51,
        "college_computer_science": 0.54,
        "college_mathematics": 0.42,
        "college_medicine": 0.6705202312138728,
        "college_physics": 0.45098039215686275,
        "computer_security": 0.81,
        "conceptual_physics": 0.5914893617021276,
        "econometrics": 0.41228070175438597,
        "electrical_engineering": 0.6551724137931034,
        "elementary_mathematics": 0.455026455026455,
        "formal_logic": 0.5555555555555556,
        "global_facts": 0.25,
        "high_school_biology": 0.8,
        "high_school_chemistry": 0.5960591133004927,
        "high_school_computer_science": 0.72,
        "high_school_european_history": 0.7515151515151515,
        "high_school_geography": 0.8333333333333334,
        "high_school_government_and_politics": 0.917098445595855,
        "high_school_macroeconomics": 0.6641025641025641,
        "high_school_mathematics": 0.37037037037037035,
        "high_school_microeconomics": 0.7563025210084033,
        "high_school_physics": 0.37748344370860926,
        "high_school_psychology": 0.8623853211009175,
        "high_school_statistics": 0.5370370370370371,
        "high_school_us_history": 0.8186274509803921,
        "high_school_world_history": 0.8270042194092827,
        "human_aging": 0.6771300448430493,
        "human_sexuality": 0.8015267175572519,
        "international_law": 0.8181818181818182,
        "jurisprudence": 0.7592592592592593,
        "logical_fallacies": 0.803680981595092,
        "machine_learning": 0.5625,
        "management": 0.8155339805825242,
        "marketing": 0.8803418803418803,
        "medical_genetics": 0.82,
        "miscellaneous": 0.8186462324393359,
        "moral_disputes": 0.7167630057803468,
        "moral_scenarios": 0.48156424581005586,
        "nutrition": 0.7516339869281046,
        "philosophy": 0.7138263665594855,
        "prehistory": 0.7037037037037037,
        "professional_accounting": 0.4432624113475177,
        "professional_law": 0.5026075619295959,
        "professional_medicine": 0.7647058823529411,
        "professional_psychology": 0.7140522875816994,
        "public_relations": 0.6909090909090909,
        "security_studies": 0.710204081632653,
        "sociology": 0.8606965174129353,
        "us_foreign_policy": 0.88,
        "virology": 0.5240963855421686,
        "world_religions": 0.8187134502923976,
        "overall": 0.6611593790058397
    }
}