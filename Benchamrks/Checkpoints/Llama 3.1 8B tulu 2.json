{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 31,
        "acc": 13.3,
        "type_acc": {
            "Algebra": 19.9,
            "Counting & Probability": 7.6,
            "Geometry": 8.1,
            "Intermediate Algebra": 5.6,
            "Number Theory": 7.4,
            "Prealgebra": 27.0,
            "Precalculus": 5.5
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 4,
        "acc": 56.8
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 3,
        "acc": 13.8
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 7,
        "acc": 23.8
    },
    "mbpp": {
        "base": {
            "pass@1": 0.5952380952380952
        },
        "+": {
            "pass@1": 0.47354497354497355
        }
    },
    "mmlu": {
        "abstract_algebra": 0.3,
        "anatomy": 0.6074074074074074,
        "astronomy": 0.6513157894736842,
        "business_ethics": 0.62,
        "clinical_knowledge": 0.7169811320754716,
        "college_biology": 0.7291666666666666,
        "college_chemistry": 0.54,
        "college_computer_science": 0.52,
        "college_mathematics": 0.39,
        "college_medicine": 0.6184971098265896,
        "college_physics": 0.4117647058823529,
        "computer_security": 0.73,
        "conceptual_physics": 0.5574468085106383,
        "econometrics": 0.4649122807017544,
        "electrical_engineering": 0.5517241379310345,
        "elementary_mathematics": 0.4074074074074074,
        "formal_logic": 0.4523809523809524,
        "global_facts": 0.34,
        "high_school_biology": 0.7129032258064516,
        "high_school_chemistry": 0.5221674876847291,
        "high_school_computer_science": 0.59,
        "high_school_european_history": 0.7151515151515152,
        "high_school_geography": 0.7676767676767676,
        "high_school_government_and_politics": 0.8290155440414507,
        "high_school_macroeconomics": 0.5897435897435898,
        "high_school_mathematics": 0.337037037037037,
        "high_school_microeconomics": 0.6848739495798319,
        "high_school_physics": 0.3708609271523179,
        "high_school_psychology": 0.8128440366972477,
        "high_school_statistics": 0.49074074074074076,
        "high_school_us_history": 0.8088235294117647,
        "high_school_world_history": 0.8143459915611815,
        "human_aging": 0.6502242152466368,
        "human_sexuality": 0.6717557251908397,
        "international_law": 0.768595041322314,
        "jurisprudence": 0.7222222222222222,
        "logical_fallacies": 0.754601226993865,
        "machine_learning": 0.48214285714285715,
        "management": 0.7864077669902912,
        "marketing": 0.8589743589743589,
        "medical_genetics": 0.7,
        "miscellaneous": 0.7879948914431673,
        "moral_disputes": 0.6473988439306358,
        "moral_scenarios": 0.3888268156424581,
        "nutrition": 0.6862745098039216,
        "philosophy": 0.6688102893890675,
        "prehistory": 0.6851851851851852,
        "professional_accounting": 0.450354609929078,
        "professional_law": 0.45371577574967403,
        "professional_medicine": 0.6507352941176471,
        "professional_psychology": 0.6666666666666666,
        "public_relations": 0.6727272727272727,
        "security_studies": 0.7346938775510204,
        "sociology": 0.8159203980099502,
        "us_foreign_policy": 0.81,
        "virology": 0.5120481927710844,
        "world_religions": 0.7719298245614035,
        "overall": 0.6119498646916394
    }
}