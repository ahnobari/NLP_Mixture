{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 43,
        "empty_samples": 24,
        "acc": 11.0,
        "type_acc": {
            "Algebra": 14.7,
            "Counting & Probability": 8.4,
            "Geometry": 10.6,
            "Intermediate Algebra": 6.4,
            "Number Theory": 8.9,
            "Prealgebra": 16.0,
            "Precalculus": 7.7
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 39,
        "empty_samples": 3,
        "acc": 22.2
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 9,
        "empty_samples": 7,
        "acc": 10.0
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 28,
        "empty_samples": 1,
        "acc": 10.0
    },
    "mbpp": {
        "base": {
            "pass@1": 0.6984126984126984
        },
        "+": {
            "pass@1": 0.5740740740740741
        }
    },
    "mmlu": {
        "abstract_algebra": 0.37,
        "anatomy": 0.6222222222222222,
        "astronomy": 0.6776315789473685,
        "business_ethics": 0.69,
        "clinical_knowledge": 0.7547169811320755,
        "college_biology": 0.7708333333333334,
        "college_chemistry": 0.53,
        "college_computer_science": 0.6,
        "college_mathematics": 0.4,
        "college_medicine": 0.7167630057803468,
        "college_physics": 0.43137254901960786,
        "computer_security": 0.83,
        "conceptual_physics": 0.574468085106383,
        "econometrics": 0.4649122807017544,
        "electrical_engineering": 0.6137931034482759,
        "elementary_mathematics": 0.4523809523809524,
        "formal_logic": 0.5793650793650794,
        "global_facts": 0.4,
        "high_school_biology": 0.7935483870967742,
        "high_school_chemistry": 0.5369458128078818,
        "high_school_computer_science": 0.68,
        "high_school_european_history": 0.7575757575757576,
        "high_school_geography": 0.8383838383838383,
        "high_school_government_and_politics": 0.9067357512953368,
        "high_school_macroeconomics": 0.6717948717948717,
        "high_school_mathematics": 0.3888888888888889,
        "high_school_microeconomics": 0.7773109243697479,
        "high_school_physics": 0.39072847682119205,
        "high_school_psychology": 0.8587155963302753,
        "high_school_statistics": 0.5694444444444444,
        "high_school_us_history": 0.8284313725490197,
        "high_school_world_history": 0.8354430379746836,
        "human_aging": 0.6995515695067265,
        "human_sexuality": 0.7862595419847328,
        "international_law": 0.8099173553719008,
        "jurisprudence": 0.7870370370370371,
        "logical_fallacies": 0.7791411042944786,
        "machine_learning": 0.5178571428571429,
        "management": 0.8155339805825242,
        "marketing": 0.8974358974358975,
        "medical_genetics": 0.82,
        "miscellaneous": 0.8186462324393359,
        "moral_disputes": 0.7225433526011561,
        "moral_scenarios": 0.43798882681564244,
        "nutrition": 0.7647058823529411,
        "philosophy": 0.729903536977492,
        "prehistory": 0.7314814814814815,
        "professional_accounting": 0.4574468085106383,
        "professional_law": 0.49022164276401564,
        "professional_medicine": 0.6985294117647058,
        "professional_psychology": 0.6977124183006536,
        "public_relations": 0.7454545454545455,
        "security_studies": 0.7224489795918367,
        "sociology": 0.8905472636815921,
        "us_foreign_policy": 0.87,
        "virology": 0.5542168674698795,
        "world_religions": 0.8070175438596491,
        "overall": 0.6597350804728671
    }
}