{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 8,
        "acc": 60.3,
        "type_acc": {
            "Algebra": 80.9,
            "Counting & Probability": 59.7,
            "Geometry": 46.8,
            "Intermediate Algebra": 36.8,
            "Number Theory": 56.3,
            "Prealgebra": 78.4,
            "Precalculus": 41.6
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 0,
        "acc": 88.6
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 1,
        "acc": 59.0
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 0,
        "acc": 44.7
    },
    "mbpp": {
        "base": {
            "pass@1": 0.335978835978836
        },
        "+": {
            "pass@1": 0.2804232804232804
        }
    },
    "mmlu": {
        "abstract_algebra": 0.37,
        "anatomy": 0.4740740740740741,
        "astronomy": 0.4934210526315789,
        "business_ethics": 0.47,
        "clinical_knowledge": 0.630188679245283,
        "college_biology": 0.5833333333333334,
        "college_chemistry": 0.37,
        "college_computer_science": 0.47,
        "college_mathematics": 0.41,
        "college_medicine": 0.5375722543352601,
        "college_physics": 0.3235294117647059,
        "computer_security": 0.64,
        "conceptual_physics": 0.425531914893617,
        "econometrics": 0.34210526315789475,
        "electrical_engineering": 0.496551724137931,
        "elementary_mathematics": 0.42857142857142855,
        "formal_logic": 0.3888888888888889,
        "global_facts": 0.34,
        "high_school_biology": 0.6903225806451613,
        "high_school_chemistry": 0.4236453201970443,
        "high_school_computer_science": 0.56,
        "high_school_european_history": 0.6060606060606061,
        "high_school_geography": 0.7525252525252525,
        "high_school_government_and_politics": 0.694300518134715,
        "high_school_macroeconomics": 0.517948717948718,
        "high_school_mathematics": 0.3925925925925926,
        "high_school_microeconomics": 0.5840336134453782,
        "high_school_physics": 0.37748344370860926,
        "high_school_psychology": 0.7522935779816514,
        "high_school_statistics": 0.5046296296296297,
        "high_school_us_history": 0.6127450980392157,
        "high_school_world_history": 0.6962025316455697,
        "human_aging": 0.5201793721973094,
        "human_sexuality": 0.6641221374045801,
        "international_law": 0.6611570247933884,
        "jurisprudence": 0.75,
        "logical_fallacies": 0.5705521472392638,
        "machine_learning": 0.44642857142857145,
        "management": 0.6796116504854369,
        "marketing": 0.7606837606837606,
        "medical_genetics": 0.59,
        "miscellaneous": 0.70242656449553,
        "moral_disputes": 0.6011560693641619,
        "moral_scenarios": 0.3139664804469274,
        "nutrition": 0.5359477124183006,
        "philosophy": 0.5691318327974276,
        "prehistory": 0.5401234567901234,
        "professional_accounting": 0.35815602836879434,
        "professional_law": 0.35919165580182527,
        "professional_medicine": 0.5698529411764706,
        "professional_psychology": 0.49019607843137253,
        "public_relations": 0.6545454545454545,
        "security_studies": 0.5959183673469388,
        "sociology": 0.6915422885572139,
        "us_foreign_policy": 0.76,
        "virology": 0.4759036144578313,
        "world_religions": 0.7368421052631579,
        "overall": 0.5277738213929639
    }
}