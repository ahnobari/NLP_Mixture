{
    "math": {
        "num_samples": 5000,
        "num_scores": 5000,
        "timeout_samples": 0,
        "empty_samples": 44,
        "acc": 42.9,
        "type_acc": {
            "Algebra": 62.2,
            "Counting & Probability": 39.0,
            "Geometry": 35.7,
            "Intermediate Algebra": 26.7,
            "Number Theory": 41.9,
            "Prealgebra": 50.9,
            "Precalculus": 25.6
        }
    },
    "gsm8k": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 0,
        "empty_samples": 3,
        "acc": 42.6
    },
    "math_oai": {
        "num_samples": 500,
        "num_scores": 500,
        "timeout_samples": 0,
        "empty_samples": 8,
        "acc": 45.4
    },
    "gsm_hard": {
        "num_samples": 1319,
        "num_scores": 1319,
        "timeout_samples": 1,
        "empty_samples": 5,
        "acc": 24.9
    },
    "mbpp": {
        "base": {
            "pass@1": 0.6640211640211641
        },
        "+": {
            "pass@1": 0.5529100529100529
        }
    },
    "mmlu": {
        "abstract_algebra": 0.34,
        "anatomy": 0.6,
        "astronomy": 0.6842105263157895,
        "business_ethics": 0.69,
        "clinical_knowledge": 0.7396226415094339,
        "college_biology": 0.75,
        "college_chemistry": 0.44,
        "college_computer_science": 0.6,
        "college_mathematics": 0.44,
        "college_medicine": 0.6936416184971098,
        "college_physics": 0.39215686274509803,
        "computer_security": 0.75,
        "conceptual_physics": 0.5446808510638298,
        "econometrics": 0.49122807017543857,
        "electrical_engineering": 0.6137931034482759,
        "elementary_mathematics": 0.4603174603174603,
        "formal_logic": 0.49206349206349204,
        "global_facts": 0.35,
        "high_school_biology": 0.7903225806451613,
        "high_school_chemistry": 0.5123152709359606,
        "high_school_computer_science": 0.68,
        "high_school_european_history": 0.7272727272727273,
        "high_school_geography": 0.8131313131313131,
        "high_school_government_and_politics": 0.8652849740932642,
        "high_school_macroeconomics": 0.6692307692307692,
        "high_school_mathematics": 0.4111111111111111,
        "high_school_microeconomics": 0.7563025210084033,
        "high_school_physics": 0.46357615894039733,
        "high_school_psychology": 0.8532110091743119,
        "high_school_statistics": 0.5601851851851852,
        "high_school_us_history": 0.8088235294117647,
        "high_school_world_history": 0.8312236286919831,
        "human_aging": 0.6547085201793722,
        "human_sexuality": 0.7557251908396947,
        "international_law": 0.7933884297520661,
        "jurisprudence": 0.7592592592592593,
        "logical_fallacies": 0.7361963190184049,
        "machine_learning": 0.5357142857142857,
        "management": 0.8155339805825242,
        "marketing": 0.8803418803418803,
        "medical_genetics": 0.76,
        "miscellaneous": 0.8058748403575989,
        "moral_disputes": 0.708092485549133,
        "moral_scenarios": 0.4301675977653631,
        "nutrition": 0.738562091503268,
        "philosophy": 0.7009646302250804,
        "prehistory": 0.6820987654320988,
        "professional_accounting": 0.45390070921985815,
        "professional_law": 0.4654498044328553,
        "professional_medicine": 0.7095588235294118,
        "professional_psychology": 0.6617647058823529,
        "public_relations": 0.7363636363636363,
        "security_studies": 0.6979591836734694,
        "sociology": 0.8606965174129353,
        "us_foreign_policy": 0.88,
        "virology": 0.5301204819277109,
        "world_religions": 0.7953216374269005,
        "overall": 0.6427859279304943
    }
}